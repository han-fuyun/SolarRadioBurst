{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model  = models.Sequential()\n",
    "#卷积层，参数意义分别为：\n",
    "#经过这一层之后，特征图的个数，一个卷积核，产生一个特征图，第一层：32，说明有32个卷积核；第二层64，说明在第一层的特征图基础上，每张特征图有两个卷积核进行特征采集\n",
    "#卷积核大小\n",
    "#激活函数\n",
    "#输入大小（只在开始的第一层有，后面不需要）\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(400,100,3)))\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#配置模型的损失函数、优化器、指标名称\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy',          #损失函数\n",
    "optimizer=optimizers.RMSprop(lr=1e-4),             #优化器\n",
    "metrics=['acc'])                                   #指标名称\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#图片的训练路径和验证路径\n",
    "train_dir = r'G:\\useful_L\\NEW_NET_3.0\\train'\n",
    "validation_dir = r'G:\\useful_L\\NEW_NET_3.0\\val'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#生成训练需要的图片和标签\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#将图片大小调整到1以内，原先图片每个像素的格式为uint8，所以要除以255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#根据目录的名称，生成对应的标签\n",
    "#train_dir有Ⅱ型和Ⅲ型的图片\n",
    "#每次生成batch_size数量的图片，图片大小为target_size\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_dir,\n",
    "target_size=(400, 100),              #生成图片的大小\n",
    "batch_size=30,                       #一次生成图片的数量\n",
    "class_mode='categorical')                 #图片标签的类型\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "validation_dir,\n",
    "target_size=(400, 100),              #生成图片的大小\n",
    "batch_size=10,                       #一次生成图片的数量\n",
    "class_mode='categorical')                 #图片标签的类型\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#开始训练\n",
    "history = model.fit_generator(\n",
    "train_generator,                           #通过生成器传入图片和标签\n",
    "steps_per_epoch=100,                       #分100次传入，每次20张\n",
    "epochs=50,                                 #总共训练40轮\n",
    "validation_data=validation_generator,      #通过生成器传入图片和标签进行验证\n",
    "validation_steps=90)                       #分90次传入，每次10张"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#绘制训练精度、验证精度\n",
    "#绘制训练损失、验证损失\n",
    "#python画图库，类似matlab的plot\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']             #得到训练的指标数据\n",
    "val_acc = history.history['val_acc']     #得到验证的指标数据\n",
    "loss = history.history['loss']           #得到训练损失\n",
    "val_loss = history.history['val_loss']   #得到验证损失\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.savefig('多分类1.0_accuracy_50.png')\n",
    "plt.legend()                              #画图例\n",
    "plt.figure()                              #另一张图\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.savefig('多分类1.0_loss_50.png')\n",
    "plt.legend()\n",
    "plt.show()                                #画图，最后加上"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存每轮的精度和损失\n",
    "\n",
    "file = open('多分类1.0_acc_loss_50.txt','a')\n",
    "file.write('训练精度：')\n",
    "for i in acc :\n",
    "    file.write(str(i))\n",
    "    file.write(\" \")\n",
    "file.write(\"\\n\")\n",
    "file.write('验证精度：')\n",
    "for i in val_acc :\n",
    "    file.write(str(i))\n",
    "    file.write(\" \")\n",
    "\n",
    "\n",
    "file.write(\"\\n\")\n",
    "file.write('训练损失：')\n",
    "for i in loss :\n",
    "    file.write(str(i))\n",
    "    file.write(\" \")\n",
    "\n",
    "file.write(\"\\n\")\n",
    "file.write('验证损失：')\n",
    "for i in val_loss :\n",
    "    file.write(str(i))\n",
    "    file.write(\" \")\n",
    "\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "III_dir = r'G:\\useful_L\\NEW_NET_2.1\\val\\III'\n",
    "O_dir = r'G:\\useful_L\\NEW_NET_2.1\\val\\other'\n",
    "n_dir = r'G:\\useful_L\\NEW_NET_2.1\\val\\noburst'\n",
    "\n",
    "def my_image(path):\n",
    "    out = []\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in filenames:\n",
    "        image = cv.imread(os.path.join(path, filename))\n",
    "\n",
    "        image = cv.resize(image, (100, 400))\n",
    "        image = image/255.0\n",
    "        out.append(image)\n",
    "    return np.array(out)\n",
    "\n",
    "imgs_III = my_image(III_dir)\n",
    "imgs_O = my_image(O_dir)\n",
    "imgs_n = my_image(n_dir)\n",
    "ret_III = model.predict_classes(imgs_III)\n",
    "ret_O = model.predict_classes(imgs_O)\n",
    "ret_n = model.predict_classes(imgs_n)\n",
    "\n",
    "ret_III = ret_III.tolist()\n",
    "ret_O = ret_O.tolist()\n",
    "true = ret_III.count([0])\n",
    "false = ret_O.count([0])\n",
    "TPR = true/len(ret_III)\n",
    "FPR = false/len(ret_O)\n",
    "print(\"TPR is :{:f} \".format(TPR))\n",
    "print(\"FPR is :{:f} \".format(FPR))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('多分类1.0.h5')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看多分类模型输出的结果的输出样式\n",
    "现在完成了III、没有爆发、其它类型  的分类网络，效果还好，96%-97%的准确率\n",
    "是不是数据包丢失了\n",
    "\n",
    "\n",
    "接下来，还要制作新的数据集\n",
    "二型爆、三型爆、四型爆、一型爆的多分类模型\n",
    "这里需要用到代价敏感损失函数\n",
    "这里完成之后，再进行Inception-Net和SPP-Net的训练工作\n",
    "\n",
    "总之 今天搞定代价敏感损失函数，制作出新的数据集，并训练出结果\n",
    "\n",
    "把各种TPR\\FPR做一遍\n",
    "明天Inception-Net搭建并训练，看情况用不用SPP-NET，用了SPP之后，在实际应用中，\n",
    "不用再进行图片的拉伸了\n",
    "\n",
    "\n",
    "good job\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 1177\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from TestModel import TestModel\n",
    "model_path = r'F:\\SolarRadioBurst\\classification\\实验1\\typeIIIMultiClassification\\多分类1.3.h5'\n",
    "path_test = r\"G:\\useful_L\\NEW_NET_3.0\\train\\other\\LM200104222255_cont+III+V_35_1801.png\"\n",
    "\n",
    "image = cv2.imread(path_test)\n",
    "image = cv2.resize(image, (100, 400))\n",
    "image = image/255.0\n",
    "out = []\n",
    "out.append(image)\n",
    "out = np.array(out)\n",
    "result = TestModel(model_path).predict_classes(out)\n",
    "print(result)\n",
    "\n",
    "# 关于predict_classes的说明，预测的结果是数字，表示对应的第几个文件夹\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}