{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras import models\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model  = models.Sequential()\n",
    "#卷积层，参数意义分别为：\n",
    "#经过这一层之后，特征图的个数，一个卷积核，产生一个特征图，第一层：32，说明有32个卷积核；第二层64，说明在第一层的特征图基础上，每张特征图有两个卷积核进行特征采集\n",
    "#卷积核大小\n",
    "#激活函数\n",
    "#输入大小（只在开始的第一层有，后面不需要）\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(800,200,3)))\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#配置模型的损失函数、优化器、指标名称\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy',          #损失函数\n",
    "optimizer=optimizers.RMSprop(lr=1e-4),             #优化器\n",
    "metrics=['acc'])                                   #指标名称\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#图片的训练路径和验证路径\n",
    "train_dir = r'G:\\test\\normal_x\\typeIII1.3\\train'\n",
    "validation_dir = r'G:\\test\\normal_x\\typeIII1.3\\val'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#生成训练需要的图片和标签\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#将图片大小调整到1以内，原先图片每个像素的格式为uint8，所以要除以255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#根据目录的名称，生成对应的标签\n",
    "#train_dir有Ⅱ型和Ⅲ型的图片\n",
    "#每次生成batch_size数量的图片，图片大小为target_size\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_dir,\n",
    "target_size=(800, 200),              #生成图片的大小\n",
    "batch_size=10,                       #一次生成图片的数量\n",
    "class_mode='binary')                 #图片标签的类型\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "validation_dir,\n",
    "target_size=(800, 200),              #生成图片的大小\n",
    "batch_size=10,                       #一次生成图片的数量\n",
    "class_mode='binary')                 #图片标签的类型\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[288512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node mul_20 (defined at D:\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_1275]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-eff5c3e3a534>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m,\u001B[0m                                 \u001B[1;31m#总共训练40轮\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvalidation_generator\u001B[0m\u001B[1;33m,\u001B[0m      \u001B[1;31m#通过生成器传入图片和标签进行验证\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m validation_steps=30)                       #每轮要传入10次，即每次30张图片进行验证\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     89\u001B[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001B[0;32m     90\u001B[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001B[1;32m---> 91\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     92\u001B[0m         \u001B[0mwrapper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_function\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit_generator\u001B[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001B[0m\n\u001B[0;32m   1730\u001B[0m             \u001B[0muse_multiprocessing\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_multiprocessing\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1731\u001B[0m             \u001B[0mshuffle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1732\u001B[1;33m             initial_epoch=initial_epoch)\n\u001B[0m\u001B[0;32m   1733\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0minterfaces\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlegacy_generator_methods_support\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training_generator.py\u001B[0m in \u001B[0;36mfit_generator\u001B[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001B[0m\n\u001B[0;32m    218\u001B[0m                                             \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    219\u001B[0m                                             \u001B[0mclass_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mclass_weight\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 220\u001B[1;33m                                             reset_metrics=False)\n\u001B[0m\u001B[0;32m    221\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m                 \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mto_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mouts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mtrain_on_batch\u001B[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001B[0m\n\u001B[0;32m   1512\u001B[0m             \u001B[0mins\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0msample_weights\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1513\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_train_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1514\u001B[1;33m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mins\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1515\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1516\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mreset_metrics\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m   3725\u001B[0m         \u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmath_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3726\u001B[0m       \u001B[0mconverted_inputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3727\u001B[1;33m     \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_graph_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mconverted_inputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3728\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3729\u001B[0m     \u001B[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1549\u001B[0m       \u001B[0mTypeError\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mFor\u001B[0m \u001B[0minvalid\u001B[0m \u001B[0mpositional\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0mkeyword\u001B[0m \u001B[0margument\u001B[0m \u001B[0mcombinations\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1550\u001B[0m     \"\"\"\n\u001B[1;32m-> 1551\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_impl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1552\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1553\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_call_impl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcancellation_manager\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, args, kwargs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1589\u001B[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001B[0;32m   1590\u001B[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001B[1;32m-> 1591\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_flat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcaptured_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcancellation_manager\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1592\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1593\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_filtered_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1690\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1691\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[1;32m-> 1692\u001B[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[0;32m   1693\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[0;32m   1694\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    543\u001B[0m               \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"executor_type\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexecutor_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"config_proto\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 545\u001B[1;33m               ctx=ctx)\n\u001B[0m\u001B[0;32m    546\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    547\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mmessage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmessage\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m     \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m     keras_symbolic_tensors = [\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\keras\\lib\\site-packages\\six.py\u001B[0m in \u001B[0;36mraise_from\u001B[1;34m(value, from_value)\u001B[0m\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m:  OOM when allocating tensor with shape[288512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node mul_20 (defined at D:\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_1275]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "history = model.fit_generator(\n",
    "train_generator,                           #通过生成器传入图片和标签\n",
    "steps_per_epoch=200,                        #每轮要传入10次，即每次100张图片进行训练\n",
    "epochs=50,                                 #总共训练40轮\n",
    "validation_data=validation_generator,      #通过生成器传入图片和标签进行验证\n",
    "validation_steps=30)                       #每轮要传入10次，即每次30张图片进行验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#绘制训练精度、验证精度\n",
    "#绘制训练损失、验证损失\n",
    "#python画图库，类似matlab的plot\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']             #得到训练的指标数据\n",
    "val_acc = history.history['val_acc']     #得到验证的指标数据\n",
    "loss = history.history['loss']           #得到训练损失\n",
    "val_loss = history.history['val_loss']   #得到验证损失\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.savefig('accuracy_1.5_50.png')\n",
    "plt.legend()                              #画图例\n",
    "plt.figure()                              #另一张图\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.savefig('loss_1.5_50.png')\n",
    "plt.legend()\n",
    "plt.show()                                #画图，最后加上"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存每轮的精度和损失\n",
    "\n",
    "file = open('acc_loss_1.5_50.txt','a')\n",
    "file.write('训练精度：')\n",
    "for i in acc :\n",
    "    file.write(str(i))\n",
    "    file.write(\" \")\n",
    "file.write(\"\\n\")\n",
    "file.write('验证精度：')\n",
    "for i in val_acc :\n",
    "    file.write(str(i))\n",
    "    file.write(\" \")\n",
    "\n",
    "\n",
    "file.write(\"\\n\")\n",
    "file.write('训练损失：')\n",
    "for i in loss :\n",
    "    file.write(str(i))\n",
    "    file.write(\" \")\n",
    "\n",
    "file.write(\"\\n\")\n",
    "file.write('验证损失：')\n",
    "for i in val_loss :\n",
    "    file.write(str(i))\n",
    "    file.write(\" \")\n",
    "\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "III_dir = r'G:\\test\\normal_x\\typeIII\\val\\III'\n",
    "O_dir = r'G:\\test\\normal_x\\typeIII\\val\\O'\n",
    "\n",
    "def my_image(path):\n",
    "    out = []\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in filenames:\n",
    "        image = cv.imread(os.path.join(path, filename))\n",
    "\n",
    "        image = cv.resize(image, (100, 400))\n",
    "        image = image/255.0\n",
    "        out.append(image)\n",
    "    return np.array(out)\n",
    "\n",
    "imgs_III = my_image(III_dir)\n",
    "imgs_O = my_image(O_dir)\n",
    "ret_III = model.predict_classes(imgs_III)\n",
    "ret_O = model.predict_classes(imgs_O)\n",
    "\n",
    "ret_III = ret_III.tolist()\n",
    "ret_O = ret_O.tolist()\n",
    "true = ret_III.count([0])\n",
    "false = ret_O.count([0])\n",
    "TPR = true/len(ret_III)\n",
    "FPR = false/len(ret_O)\n",
    "print(\"TPR is :{:f} \".format(TPR))\n",
    "print(\"FPR is :{:f} \".format(FPR))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('typeIII_binary_normalization_100_1.5_50.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}